{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "bert-reco-system.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "15u3WRgp2bKVY5A4hblUzvE1X_aJurA-Q",
      "authorship_tag": "ABX9TyPZVzIMuwzx+vqASxMTLusn",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MaQuest/Summer2021/blob/main/bert_reco_system.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "2GLIJqtDBe9S",
        "outputId": "21fa5d91-097f-4cae-fab1-b28d4b869b63"
      },
      "source": [
        "!pip install sentence-transformers\n",
        "!pip install tweepy\n",
        "!pip install bert-extractive-summarizer\n",
        "!pip install nltk\n",
        "!pip install google-cloud-vision"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting sentence-transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/cc/75/df441011cd1726822b70fbff50042adb4860e9327b99b346154ead704c44/sentence-transformers-1.2.0.tar.gz (81kB)\n",
            "\u001b[K     |████████████████████████████████| 81kB 4.2MB/s \n",
            "\u001b[?25hCollecting transformers<5.0.0,>=3.1.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d5/43/cfe4ee779bbd6a678ac6a97c5a5cdeb03c35f9eaebbb9720b036680f9a2d/transformers-4.6.1-py3-none-any.whl (2.2MB)\n",
            "\u001b[K     |████████████████████████████████| 2.3MB 10.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (4.41.1)\n",
            "Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (1.8.1+cu101)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (0.9.1+cu101)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (1.19.5)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (0.22.2.post1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (1.4.1)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (3.2.5)\n",
            "Collecting sentencepiece\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f5/99/e0808cb947ba10f575839c43e8fafc9cc44e4a7a2c8f79c60db48220a577/sentencepiece-0.1.95-cp37-cp37m-manylinux2014_x86_64.whl (1.2MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2MB 22.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=3.1.0->sentence-transformers) (2.23.0)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=3.1.0->sentence-transformers) (4.5.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=3.1.0->sentence-transformers) (2019.12.20)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/75/ee/67241dc87f266093c533a2d4d3d69438e57d7a90abb216fa076e7d475d4a/sacremoses-0.0.45-py3-none-any.whl (895kB)\n",
            "\u001b[K     |████████████████████████████████| 901kB 51.3MB/s \n",
            "\u001b[?25hCollecting huggingface-hub==0.0.8\n",
            "  Downloading https://files.pythonhosted.org/packages/a1/88/7b1e45720ecf59c6c6737ff332f41c955963090a18e72acbcbeac6b25e86/huggingface_hub-0.0.8-py3-none-any.whl\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=3.1.0->sentence-transformers) (20.9)\n",
            "Collecting tokenizers<0.11,>=0.10.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/e2/df3543e8ffdab68f5acc73f613de9c2b155ac47f162e725dcac87c521c11/tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3MB)\n",
            "\u001b[K     |████████████████████████████████| 3.3MB 48.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=3.1.0->sentence-transformers) (3.0.12)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.6.0->sentence-transformers) (3.7.4.3)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.7/dist-packages (from torchvision->sentence-transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sentence-transformers) (1.0.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from nltk->sentence-transformers) (1.15.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers<5.0.0,>=3.1.0->sentence-transformers) (2021.5.30)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers<5.0.0,>=3.1.0->sentence-transformers) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers<5.0.0,>=3.1.0->sentence-transformers) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers<5.0.0,>=3.1.0->sentence-transformers) (3.0.4)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers<5.0.0,>=3.1.0->sentence-transformers) (3.4.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers<5.0.0,>=3.1.0->sentence-transformers) (7.1.2)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers<5.0.0,>=3.1.0->sentence-transformers) (2.4.7)\n",
            "Building wheels for collected packages: sentence-transformers\n",
            "  Building wheel for sentence-transformers (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sentence-transformers: filename=sentence_transformers-1.2.0-cp37-none-any.whl size=123339 sha256=1df5eb8dd7da89bd71c4aecf2a079fd6cc2e5173f6e319ce631970bb87638098\n",
            "  Stored in directory: /root/.cache/pip/wheels/0f/06/f7/faaa96fdda87462b4fd5c47b343340e9d5531ef70d0eef8242\n",
            "Successfully built sentence-transformers\n",
            "Installing collected packages: sacremoses, huggingface-hub, tokenizers, transformers, sentencepiece, sentence-transformers\n",
            "Successfully installed huggingface-hub-0.0.8 sacremoses-0.0.45 sentence-transformers-1.2.0 sentencepiece-0.1.95 tokenizers-0.10.3 transformers-4.6.1\n",
            "Requirement already satisfied: tweepy in /usr/local/lib/python3.7/dist-packages (3.10.0)\n",
            "Requirement already satisfied: requests[socks]>=2.11.1 in /usr/local/lib/python3.7/dist-packages (from tweepy) (2.23.0)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from tweepy) (1.3.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tweepy) (1.15.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy) (2021.5.30)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6; extra == \"socks\" in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy) (1.7.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->tweepy) (3.1.1)\n",
            "Collecting bert-extractive-summarizer\n",
            "  Downloading https://files.pythonhosted.org/packages/1a/07/fdb05f9e18b6f641499ef56737126fbd2fafe1cdc1a04ba069d5aa205901/bert_extractive_summarizer-0.7.1-py3-none-any.whl\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (from bert-extractive-summarizer) (4.6.1)\n",
            "Requirement already satisfied: spacy in /usr/local/lib/python3.7/dist-packages (from bert-extractive-summarizer) (2.2.4)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from bert-extractive-summarizer) (0.22.2.post1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers->bert-extractive-summarizer) (20.9)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers->bert-extractive-summarizer) (2019.12.20)\n",
            "Requirement already satisfied: huggingface-hub==0.0.8 in /usr/local/lib/python3.7/dist-packages (from transformers->bert-extractive-summarizer) (0.0.8)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers->bert-extractive-summarizer) (2.23.0)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers->bert-extractive-summarizer) (4.5.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers->bert-extractive-summarizer) (4.41.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers->bert-extractive-summarizer) (3.0.12)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers->bert-extractive-summarizer) (0.0.45)\n",
            "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers->bert-extractive-summarizer) (0.10.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers->bert-extractive-summarizer) (1.19.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy->bert-extractive-summarizer) (1.0.5)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy->bert-extractive-summarizer) (3.0.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy->bert-extractive-summarizer) (57.0.0)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy->bert-extractive-summarizer) (0.8.2)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy->bert-extractive-summarizer) (7.4.0)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy->bert-extractive-summarizer) (2.0.5)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy->bert-extractive-summarizer) (1.0.5)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy->bert-extractive-summarizer) (0.4.1)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.7/dist-packages (from spacy->bert-extractive-summarizer) (1.1.3)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from spacy->bert-extractive-summarizer) (1.0.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->bert-extractive-summarizer) (1.0.1)\n",
            "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->bert-extractive-summarizer) (1.4.1)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers->bert-extractive-summarizer) (2.4.7)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers->bert-extractive-summarizer) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers->bert-extractive-summarizer) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers->bert-extractive-summarizer) (2021.5.30)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers->bert-extractive-summarizer) (3.0.4)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers->bert-extractive-summarizer) (3.4.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers->bert-extractive-summarizer) (3.7.4.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers->bert-extractive-summarizer) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers->bert-extractive-summarizer) (7.1.2)\n",
            "Installing collected packages: bert-extractive-summarizer\n",
            "Successfully installed bert-extractive-summarizer-0.7.1\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (3.2.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from nltk) (1.15.0)\n",
            "Collecting google-cloud-vision\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0a/51/e6321162877a2903ba3158737b944cf582a62b7f045e22864ab56b764adc/google_cloud_vision-2.3.1-py2.py3-none-any.whl (461kB)\n",
            "\u001b[K     |████████████████████████████████| 471kB 5.2MB/s \n",
            "\u001b[?25hCollecting proto-plus>=1.15.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b4/8a/61c5a9b9b6288f9b060b6e3d88374fc083953a29aeac7206616c2d3c9c8e/proto_plus-1.18.1-py3-none-any.whl (42kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 7.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: google-api-core[grpc]<2.0.0dev,>=1.22.2 in /usr/local/lib/python3.7/dist-packages (from google-cloud-vision) (1.26.3)\n",
            "Requirement already satisfied: protobuf>=3.12.0 in /usr/local/lib/python3.7/dist-packages (from proto-plus>=1.15.0->google-cloud-vision) (3.12.4)\n",
            "Requirement already satisfied: google-auth<2.0dev,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from google-api-core[grpc]<2.0.0dev,>=1.22.2->google-cloud-vision) (1.31.0)\n",
            "Requirement already satisfied: setuptools>=40.3.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core[grpc]<2.0.0dev,>=1.22.2->google-cloud-vision) (57.0.0)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core[grpc]<2.0.0dev,>=1.22.2->google-cloud-vision) (1.53.0)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.7/dist-packages (from google-api-core[grpc]<2.0.0dev,>=1.22.2->google-cloud-vision) (2018.9)\n",
            "Requirement already satisfied: requests<3.0.0dev,>=2.18.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core[grpc]<2.0.0dev,>=1.22.2->google-cloud-vision) (2.23.0)\n",
            "Requirement already satisfied: six>=1.13.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core[grpc]<2.0.0dev,>=1.22.2->google-cloud-vision) (1.15.0)\n",
            "Requirement already satisfied: packaging>=14.3 in /usr/local/lib/python3.7/dist-packages (from google-api-core[grpc]<2.0.0dev,>=1.22.2->google-cloud-vision) (20.9)\n",
            "Requirement already satisfied: grpcio<2.0dev,>=1.29.0; extra == \"grpc\" in /usr/local/lib/python3.7/dist-packages (from google-api-core[grpc]<2.0.0dev,>=1.22.2->google-cloud-vision) (1.34.1)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2.0dev,>=1.21.1->google-api-core[grpc]<2.0.0dev,>=1.22.2->google-cloud-vision) (4.2.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.6\" in /usr/local/lib/python3.7/dist-packages (from google-auth<2.0dev,>=1.21.1->google-api-core[grpc]<2.0.0dev,>=1.22.2->google-cloud-vision) (4.7.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2.0dev,>=1.21.1->google-api-core[grpc]<2.0.0dev,>=1.22.2->google-cloud-vision) (0.2.8)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core[grpc]<2.0.0dev,>=1.22.2->google-cloud-vision) (2021.5.30)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core[grpc]<2.0.0dev,>=1.22.2->google-cloud-vision) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core[grpc]<2.0.0dev,>=1.22.2->google-cloud-vision) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core[grpc]<2.0.0dev,>=1.22.2->google-cloud-vision) (1.24.3)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=14.3->google-api-core[grpc]<2.0.0dev,>=1.22.2->google-cloud-vision) (2.4.7)\n",
            "Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.7/dist-packages (from rsa<5,>=3.1.4; python_version >= \"3.6\"->google-auth<2.0dev,>=1.21.1->google-api-core[grpc]<2.0.0dev,>=1.22.2->google-cloud-vision) (0.4.8)\n",
            "Installing collected packages: proto-plus, google-cloud-vision\n",
            "Successfully installed google-cloud-vision-2.3.1 proto-plus-1.18.1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "google"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-GC0RQ92BmAD"
      },
      "source": [
        "import pandas as pd\n",
        "import json\n",
        "import os\n",
        "from sentence_transformers import SentenceTransformer, util\n",
        "from google.colab import drive\n",
        "import tweepy\n",
        "import re\n",
        "import os,io\n",
        "from google.cloud import vision\n",
        "from google.cloud.vision_v1 import types\n",
        "import pandas as pd\n",
        "import nltk\n",
        "\n",
        "ACCESS_TOKEN=\"1401579178072231936-98mY1wOw1UR3GHOjdo4ePnfdfUHt6n\"\n",
        "ACESS_TOKEN_SECRET=\"QiIslicgx8GNGrGDPrx8xNZc2WoCyrUsZumgXSyGzGLOx\"\n",
        "CONSUMER_KEY=\"uaiStuv7EYdYxWSomPKHvSSF5\"\n",
        "CONSUMER_SECRET=\"JOQryy37w9HPMSrSw8msyyb048iqeHmK4xCRyWP1oBhLKwLYlb\"\n",
        "\n",
        "auth=tweepy.OAuthHandler(CONSUMER_KEY,CONSUMER_SECRET)\n",
        "auth.set_access_token(ACCESS_TOKEN,ACESS_TOKEN_SECRET)\n",
        "api=tweepy.API(auth)\n",
        "\n",
        "os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = 'seismic-diorama-316110-5569927e0d86.json'\n",
        "client = vision.ImageAnnotatorClient()"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6o4F0RJhxPqt"
      },
      "source": [
        "def pre_process(tweets):\n",
        "\n",
        "    for i in range(0, len(tweets)):\n",
        "\n",
        "        if (tweets[i] is not None):\n",
        "\n",
        "            if(tweets[i]!=tweets[i]):\n",
        "                tweets[i]=\"\"\n",
        "\n",
        "            tweets[i] = tweets[i].lower()  # To lower case\n",
        "            tweets[i] = tweets[i].replace('@','')  # remove @\n",
        "            tweets[i] = tweets[i].replace('#','')  # remove #\n",
        "            tweets[i] = remove_urls(tweets[i])  # remove URL\n",
        "            tweets[i] = remove_emojis(tweets[i])  # remove emojis\n",
        "            tweets[i] = \"\".join(j for j in tweets[i] if j not in (\n",
        "            \"?\", \".\", \";\", \":\", \"!\", \"-\", \",\", \"[\", \"]\", \"(\", \")\", \"’\", \"‘\", '\"', \"$\", \"'\", \"“\", \"”\", \"•\", \"=\", \"+\",\n",
        "            \"%\", \"/\", \"&\", \"|\", \"~\"))  # remove punctuations\n",
        "            tweets[i] = removeNonEnglishWordsFunct(tweets[i])\n",
        "\n",
        "    return tweets\n",
        "\n",
        "def remove_urls (str):\n",
        "\n",
        "    str = re.sub(r'(https|http)?:\\/\\/(\\w|\\.|\\/|\\?|\\=|\\&|\\%)*\\b', '', str, flags=re.MULTILINE)\n",
        "    return(str)\n",
        "\n",
        "\n",
        "def remove_emojis(data):\n",
        "\n",
        "    emoji = re.compile(\"[\"\n",
        "        u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
        "        u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
        "        u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
        "        u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
        "        u\"\\U00002500-\\U00002BEF\"  # chinese char\n",
        "        u\"\\U00002702-\\U000027B0\"\n",
        "        u\"\\U00002702-\\U000027B0\"\n",
        "        u\"\\U000024C2-\\U0001F251\"\n",
        "        u\"\\U0001f926-\\U0001f937\"\n",
        "        u\"\\U00010000-\\U0010ffff\"\n",
        "        u\"\\u2640-\\u2642\" \n",
        "        u\"\\u2600-\\u2B55\"\n",
        "        u\"\\u200d\"\n",
        "        u\"\\u23cf\"\n",
        "        u\"\\u23e9\"\n",
        "        u\"\\u231a\"\n",
        "        u\"\\ufe0f\"  # dingbats\n",
        "        u\"\\u3030\"\n",
        "                      \"]+\", re.UNICODE)\n",
        "    return re.sub(emoji, '', data)\n",
        "\n",
        "def removeNonEnglishWordsFunct(x):\n",
        "\n",
        "    new_string=re.sub('[^a-zA-Z0-9]',' ',x)\n",
        "\n",
        "    cleaned_string=re.sub('\\s+',' ',new_string)\n",
        "    return cleaned_string"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WHsHsl0iBoIv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ec04d3e1-8c94-4051-9857-4786c083c7a4"
      },
      "source": [
        "df = pd.read_csv('ccc-organizations-2011_1.csv')\n",
        "\n",
        "charities =df.OrganizationName.values+\" \"+df.Description.values+\" \"+df.City.values\n",
        "\n",
        "print(len(charities), \"Charities\")\n",
        "\n",
        "#We then load the allenai-specter model with SentenceTransformers\n",
        "model = SentenceTransformer('allenai-specter')\n",
        "\n",
        "#To encode the descriptions to a single string\n",
        "charity_texts = [charity for charity in charities]\n",
        "\n",
        "#Compute embeddings for all descriptions\n",
        "corpus_embeddings = model.encode(charity_texts, convert_to_tensor=True)\n"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "318 Charities\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8onBq7McJVg6"
      },
      "source": [
        "\n",
        "\n",
        "\n",
        "from termcolor import colored\n",
        "\n",
        "\n",
        "def search_papers(title):\n",
        "\n",
        "   print(title)\n",
        "   query_embedding = model.encode(title+'[SEP]', convert_to_tensor=True) # Converts to tensor\n",
        "   search_hits = util.semantic_search(query_embedding, corpus_embeddings)\n",
        "   search_hits = search_hits[0]\n",
        "   count = 0\n",
        "   top_header = \"\\n\\nTop 10 related charities\\n\\n\"\n",
        "   print(colored(top_header,'blue'))\n",
        "\n",
        "   for hit in search_hits:\n",
        "\n",
        "         related_charities = charities[hit['corpus_id']]\n",
        "         count += 1\n",
        "         subsetDataFrame = df[df['OrganizationName']+\" \"+df['Description']+\" \"+df['City']== related_charities]\n",
        "         k=subsetDataFrame.values\n",
        "         print(\"\\n\"+str(count)+\") \"+colored(str(k[0][1]), 'red'))\n",
        "         print(\"similiarity score of \" + str(format(search_hits[count-1]['score'],\".2f\")))\n",
        "         print(\"Description of charity : \" +related_charities)\n",
        "\n",
        "\n",
        "#want to make a big impact donations made through birdies4kids for the alberta diabetes foundation are matched up to 50  birdies for kids runs until august 15th 2021  to donate and read more \n",
        "\n",
        "#alberta wins reddeer sisters donate land to nature conservancy of canada ncc preserve a haven for species wildlife ruth dorothy bower donate 193 hectares of land on the west bank of the reddeer river bowerwildlifesanctuary\n",
        "\n",
        "#in the news the kidney foundation encourages other canadian organizations and companies to to adopt policies to support living organdonors read more about kidneycanada s wage replacement policy for living organ and tissue donation\n",
        "\n",
        "#participate in the scotiabank calgary marathon charity challenge to help children amp families at childrens cottage society theres an event for everyone of all abilities register or donate at  thanks for your consideration children families \n",
        "\n",
        "#can you help us many children need their very own books strong reading role models amp safe fun reading spaces your donation helps more children experience the magic of reading amp a lifetime of opportunity "
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LNG7tMsW1gM6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ac10ba64-9b64-4647-acd0-10b2af643669"
      },
      "source": [
        "print(\"What basis do you want to generate a recommendation on ? \")\n",
        "print(\"\\n1. Enter a sentence  \")\n",
        "print(\"2. Trending tweet on a particular hashtag \")\n",
        "print(\"3. Image-based recommendation generation \\n\")\n",
        "choice=input(\"Enter your choice : \")\n",
        "\n",
        "if(choice==\"1\"):\n",
        "\n",
        "  title=input(\"\\nEnter a sentence : \")\n",
        "  enable_loc=str(input(\"Do you wish to enable location ? \"))\n",
        "  if(enable_loc==\"yes\"):\n",
        "    location=str(input(\"Enter location : \"))\n",
        "    search_papers(title+\" \"+location)\n",
        "  else:\n",
        "    search_papers(title)\n",
        "\n",
        "elif(choice==\"2\"):\n",
        "\n",
        "  tag = input(\"\\nEnter a hashtag : \")\n",
        "  tweets=tweepy.Cursor(api.search,q=tag,result_type='popular',tweet_mode=\"extended\").items(1)\n",
        "  temp=[]\n",
        "  for tweet in tweets :\n",
        "\n",
        "      temp.append(tweet.full_text)\n",
        "\n",
        "  temp=pre_process(temp)\n",
        "  tweet=temp[0]\n",
        "  print(\"\\nMost famous tweet : \\n\"+colored(tweet,'red'))\n",
        "  search_papers(tweet)\n",
        "\n",
        "elif(choice==\"3\"):\n",
        "\n",
        "  with io.open(\"horse.jpg\", 'rb') as image_file:\n",
        "    content = image_file.read()\n",
        "\n",
        "\n",
        "  sample_tweet = \"\"\"Beautiful Rose (R) and beautiful Sunflower (L) are seen here enjoying a breezy afternoon here at the ranch. \n",
        "\n",
        "  Sparkleshttp://linktr.ee/PRRHR\n",
        "\n",
        "  #miniturehorses #horse #rescue #minihorsesoftwitter #BestFriendsDay #donate #tuesdayvibe\"\"\"\n",
        "\n",
        "  sample_tweet=pre_process([sample_tweet])\n",
        "\n",
        "  image = vision.Image(content=content)\n",
        "\n",
        "  response_label = client.label_detection(image=image)\n",
        "  response_text = client.text_detection(image=image)\n",
        "\n",
        "  temp=\"\"\n",
        "  count=0\n",
        "\n",
        "  for label in response_label.label_annotations:\n",
        "      if(count<3):\n",
        "        temp+=label.description+\" \"\n",
        "        count+=1\n",
        "\n",
        "  for r in response_text.text_annotations:\n",
        "      temp+=r.description+\" \"\n",
        "\n",
        "\n",
        "  temp=pre_process([temp])\n",
        "  print(\"\\n\\nInterpretation of tweet : \"+colored(sample_tweet[0]+\" \"+temp[0],'red'))\n",
        "  search_papers(sample_tweet[0]+\" \"+temp[0])"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "What basis do you want to generate a recommendation on ? \n",
            "\n",
            "1. Enter a sentence  \n",
            "2. Trending tweet on a particular hashtag \n",
            "3. Image-based recommendation generation \n",
            "\n",
            "Enter your choice : 1\n",
            "\n",
            "Enter a sentence : baltimore\n",
            "Do you wish to enable location ? no\n",
            "baltimore\n",
            "\u001b[34m\n",
            "\n",
            "Top 10 related charities\n",
            "\n",
            "\u001b[0m\n",
            "\n",
            "1) \u001b[31mMECU Foundation, Inc.\u001b[0m\n",
            "similiarity score of 0.78\n",
            "Description of charity : MECU Foundation, Inc. The foundation raises money for our 6 partner elementary schools and for a college scholarship fund. Baltimore\n",
            "\n",
            "2) \u001b[31mCenter Stage Associates, Inc.\u001b[0m\n",
            "similiarity score of 0.75\n",
            "Description of charity : Center Stage Associates, Inc. Engages a diverse audience of approximately 100,000 annually, featuring professional theatrical productions, enhanced by artistic educational and community programming. Baltimore\n",
            "\n",
            "3) \u001b[31mCatholic Charities (Associated Catholic Charities)\u001b[0m\n",
            "similiarity score of 0.74\n",
            "Description of charity : Catholic Charities (Associated Catholic Charities) Maryland's leading private provider of human services, over 80 programs include Our Daily Bread, Christopher Place, Sarah's House, St. Vincent's Villa, Anna's House and Villa Maria. Baltimore\n",
            "\n",
            "4) \u001b[31mBlack Cherry, Inc.\u001b[0m\n",
            "similiarity score of 0.73\n",
            "Description of charity : Black Cherry, Inc. An award-winning and acclaimed association of artists and performers dedicated to puppetry arts. Presents spell binding performances and engaging educational programs to understand communities throughout Maryland. Baltimore\n",
            "\n",
            "5) \u001b[31mStella Maris, Inc.\u001b[0m\n",
            "similiarity score of 0.72\n",
            "Description of charity : Stella Maris, Inc. Provides services for the elderly, sick and dying including long-term care, rehabilitation, dementia care, home care, senior day care and hospice. Timonium\n",
            "\n",
            "6) \u001b[31mVolunteer Central, Inc.\u001b[0m\n",
            "similiarity score of 0.72\n",
            "Description of charity : Volunteer Central, Inc. Strengthens the community by inspiring volunteerism, connecting motivated people and businesses to non-profit organizations and creating thousands of volunteer and board opportunities yearly. Baltimore\n",
            "\n",
            "7) \u001b[31mBaltimore Reads, Inc.\u001b[0m\n",
            "similiarity score of 0.72\n",
            "Description of charity : Baltimore Reads, Inc. Instructs adults in reading, writing, mathematics and employment readiness skills and offers ESOL. Our Book Bank collects and distributes free books for kids. Baltimore\n",
            "\n",
            "8) \u001b[31mAmerica's Charities\u001b[0m\n",
            "similiarity score of 0.72\n",
            "Description of charity : America's Charities Working to build strong communities.  Addressing needs of children, families and communities through member programs, by helping employers and employees support our members charities programs. Chantilly\n",
            "\n",
            "9) \u001b[31mReading Is Fundamental\u001b[0m\n",
            "similiarity score of 0.71\n",
            "Description of charity : Reading Is Fundamental RIF provides free books for children nationwide and engages children, parents, and communities in reading and motivational activities to encourage a lifelong love of reading. Washington\n",
            "\n",
            "10) \u001b[31mLeukemia & Lymphoma Society, MD Chapter\u001b[0m\n",
            "similiarity score of 0.71\n",
            "Description of charity : Leukemia & Lymphoma Society, MD Chapter Funds research to cure leukemia, lymphoma, Hodgkin's disease and myeloma; provides patient services, information and referral, financial assistance, education, advocacy and support groups. Hunt Valley\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}